---
title: "Differences LPA"
author: "Will A. S. Hardy"
date: "27/01/2021"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
library(tidyverse)
library(tsibble)
library(tidyLPA)
library(future)
library(furrr)
library(tidymodels)
library(workflows)
library(tune)
library(nnet)

knitr::opts_chunk$set(echo = TRUE)

set.seed(32)

gp <- 
  read_rds("../OneDrive/2_interimdata/8_linkeddata/gp_agesex_qof_combined.rds") %>% 
  mutate(npat = N,
         N = NULL,
         practice_id = as_factor(practiceid),
         dispensing = as_factor(dispensing),
         hboard = as_factor(str_remove_all(hboard, "W110000"))) %>% 
  ungroup() %>% 
  janitor::clean_names()

differences_files <- 
  list.files("../data/differences/")
names(differences_files) <- 
  str_remove_all(differences_files, "_discreps.rds")

differences <- 
  map_dfr(.x = differences_files,
          .f = ~read_rds(paste0("../data/differences/", .x)),
          .id = "drug") %>% 
  mutate(drug = as_factor(drug)) %>% 
  select(drug, regional_unit, datename, discrepancy)

proportions <- 
  map_dfr(.x = differences_files,
          .f = ~read_rds(paste0("../data/differences/", .x)),
          .id = "drug") %>% 
  mutate(drug = as_factor(drug)) %>% 
  select(drug, regional_unit, datename, prop)

drugs <- unique(as.character(differences$drug))

```

## Identifying different prescribing behaviours - LPA

* What is LPA
  * Differences from clustering methods (e.g., k-means and hierarchical)

When conducting LPA, several models are specified and then evaluated. Model selection, including class enumeration, should not be based solely on statistical criteria, but also the statistical adequacy and substantive meaning of the solutions [@Marsh2009; @Morin2016]. Indeed, relying solely on statistical criteria in large samples may lead to the inability to identify an "optimal solution" as model fit increases as the number of classes increase [@Morin2009].

In this study we inspected the Bayesian Information Criterion [BIC; @Schwartz1978] and the bootstrapped likelihood ratio test [BLRT; @McLachlan2000] during the class enumeration process as the results of Monte-Carlo simulation study [@Nylund2007] showed them outperform other information criteria and likelihood-based tests. 

* Entropy
* Posterior probabilities

## Data cleaning

```{r, data-problem-values, warning=FALSE}
differences %>% 
  pivot_wider(names_from = datename, values_from = discrepancy) %>% 
  psych::describeBy(group = "drug", fast = TRUE)

proportions %>% 
  pivot_wider(names_from = datename, values_from = prop) %>% 
  psych::describeBy(group = "drug", fast = TRUE)
```

* Problem with `oac` data
* Infinite values have been calculated when something has been divided by zero. Is this when the total prescribing of oac has been zero, thus wafarin as a percentage of 0 is Inf?

```{r, data-which-problem}
differences %>% 
  filter(drug == "oac" & 
           (is.na(discrepancy) | is.nan(discrepancy) | is.infinite(discrepancy))) %>% 
  group_by(datename) %>% 
  count()

differences %>% 
  filter(drug == "oac" & 
           (is.na(discrepancy) | is.nan(discrepancy) | is.infinite(discrepancy))) %>% 
  group_by(drug, regional_unit) %>% 
  count()
```

* Missing/inappropriate data in five practices
* Removed these practices from the `oac` data

```{r, data-cleaning}
differences <- 
  differences %>% 
  anti_join(y = differences %>% 
              filter(drug == "oac" & 
                       (is.na(discrepancy) |
                          is.nan(discrepancy) | 
                          is.infinite(discrepancy))) %>% 
              group_by(drug, regional_unit) %>% 
              count(), 
            by = c("drug", "regional_unit"))

differences_wide <- 
  differences %>% 
  pivot_wider(names_from = datename, values_from = discrepancy)

proportions_wide <- 
  proportions %>% 
  pivot_wider(names_from = datename, values_from = prop)
```


## Disease profiles

```{r}
df <- select(filter(gp, year == "2020"), chd:flu)
psych::fa.parallel(df)
five_fac <- psych::fa(df, nfactors = 3, rotate = "varimax")
print(five_fac$loadings, cutoff = .2)

dis_pca <- psych::principal(df, nfactors = 3, scores = TRUE)
plot(dis_pca$values)
dis_pca$rotation
dis_pca_scores <- bind_cols(practice_id = filter(gp, year == "2020")$practice_id, dis_pca$scores)

# 2d plot
x <- dis_pca$loadings[,1]
y <- dis_pca$loadings[,2]
z <- dis_pca$loadings[,3]

pca_plot_df <- bind_cols(dis = names(x), x = x, y = y, z = z)

ggplot(aes(x = x, y = y), data = pca_plot_df) +
  geom_text(aes(label = dis))

ggplot(aes(x = x, y = z), data = pca_plot_df) +
  geom_text(aes(label = dis))

# 3d plot
plotly::plot_ly(x=x, y=y, z=z, data = pca_plot_df,
                type="scatter3d", mode="markers", color="dis")
```


## Latent profile analysis

When conducting LPA, several models are specified and then evaluated. Model selection, including class enumeration, should not be based solely on statistical criteria, but also the statistical adequacy and substantive meaning of the solutions [@Marsh2009; @Morin2016]. Indeed, relying solely on statistical criteria in large samples may lead to the inability to identify an "optimal solution" as model fit increases as the number of classes increase [@Morin2009].

In this study we inspected the Bayesian Information Criterion [BIC; @someone], the bootstrapped likelihood ratio test [BLRT; @someone], the sample adjusted BIC [SABIC; @someone], and an analytical hierarchy proposed by Akogul & Erisoglu [-@Akogul2017] which evaluates five information criteria simultaneously. 

* Entropy


### ace

#### difference
##### LPA estimation

```{r, ace-lpa-diff}
tictoc::tic()
ace_lpa <- 
  differences_wide %>% 
  filter(drug == "ace" & `2020 May` > -100) %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:6,
                    models = c(1:3))
tictoc::toc()
```

##### LPA model selection

```{r, ace-fits-diff}
ace_lpa

ace_lpa_fits <- compare_solutions(ace_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
ace_lpa_fits

ace_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* AIC, BIC, SABIC all suggest model 2 is best fit with 6, 4, 6 classes
* BLRT < 6 classes for model 2
  * AIC and SABIC suggest 5 classes are best when BLRT threshold applied
* Entropy decreases when increasing from 4 to 5 classes
* Selected model 2 with 4 classes.


```{r}
ace_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "ace" & `2020 May` > -100) %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, ace-profile-vis-diff}
ace_lpa$model_2_class_4 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  ace_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

ace_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

ace_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```

* Class 1 - 
* Class 2 - 
* Class 3 - 
* Class 4 - 


##### Weka data

```{r, ace-weka-diff}
ace_lpa$model_2_class_4 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, where(is.character), practice_id), Class) %>% 
  mutate(across(where(is.numeric), scale)) %>% 
  write_csv("../data/weka/ace.csv")
```


##### Multinomial logistic regression

```{r, ace-multinom-diff-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

ace_multinom_data <- 
  ace_lpa$model_2_class_4 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>% 
  mutate(gp_load = npat/ngp) %>% 
  select(Class, pm_65, p_fem, hyp, ast, wimd2019, dispensing, ngp, gp_load, hboard) %>% # Removed chd, p_male, pf_65, pm_65, npat to reduce multicollinearity issues
  mutate(Class = as.factor(Class),
         hboard = as.factor(hboard),
         across(where(is.numeric), ~normalize(.)))

ace_multinom_data %>% 
  DataExplorer::plot_correlation()
```


###### Class 1 ref

```{r, ace-multinom-diff-ref1}
# Class 1 as ref class
ace_multinom_data$Class <- relevel(ace_multinom_data$Class, ref = "1")
ace_m1 <- 
  ace_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_m1)
print("relative risk"); exp(coef(ace_m1))

ace_m1_z <- summary(ace_m1)$coefficients/summary(ace_m1)$standard.errors
#ace_m1_z

# Two-tailed z-test
print("Wald test p-value")
ace_m1_p <- (1 - pnorm(abs(ace_m1_z), 0, 1)) * 2
ace_m1_p
```


###### Class 2 ref

```{r, ace-multinom-diff-ref2}
# Class 2 as ref class
ace_multinom_data$Class <- relevel(ace_multinom_data$Class, ref = "2")
ace_m2 <- 
  ace_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_m2)
print("relative risk"); exp(coef(ace_m2))

ace_m2_z <- summary(ace_m2)$coefficients/summary(ace_m2)$standard.errors
# ace_m2_z

# Two-tailed z-test
print("Wald test p-value")
ace_m2_p <- (1 - pnorm(abs(ace_m2_z), 0, 1)) * 2
ace_m2_p
```


###### Class 3 ref

```{r, ace-multinom-diff-ref3}
# Class 3 as ref class
ace_multinom_data$Class <- relevel(ace_multinom_data$Class, ref = "3")
ace_m3 <- 
  ace_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_m3)
print("relative risk"); exp(coef(ace_m3))

ace_m3_z <- summary(ace_m3)$coefficients/summary(ace_m3)$standard.errors
# ace_m3_z

# Two-tailed z-test
print("Wald test p-value")
ace_m3_p <- (1 - pnorm(abs(ace_m3_z), 0, 1)) * 2
ace_m3_p
```



```{r}
ace_multinom_data %>% 
  group_by(Class) %>% 
  summarise(dispensing = sum(if_else(as.character(dispensing) == "Yes", 1, 0))/n())
```


#### proportion
##### LPA estimation

```{r}
proportions %>% 
  filter(drug == "ace") %>% 
  ggplot(aes(x = prop)) + 
  geom_histogram() +
  facet_wrap(~as.factor(datename))
```


```{r, ace-lpa-prop}
tictoc::tic()
ace_prop_lpa <- 
  proportions_wide %>% 
  filter(drug == "ace") %>%
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
tictoc::toc()
```

##### LPA model selection

```{r, ace-fits-prop}
ace_prop_lpa

ace_prop_lpa_fits <- compare_solutions(ace_prop_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
ace_prop_lpa_fits

ace_prop_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* Selected model 2 with 6 classes.


```{r, ace-prop-profile-plots}
ace_prop_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "ace" & `2020 Jul` > -50) %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, ace-profile-vis-prop}
ace_prop_lpa$model_2_class_6 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .2) +
  stat_summary(fun = "mean", size = .1) +
  facet_wrap(~Class) +
  theme(legend.position = "none") +
  coord_cartesian(ylim = c(.5, 1.5))

ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Jul` ~ Class, data = .) %>% 
  summary()

ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Jul` ~ Class, data = .) %>% 
  TukeyHSD()

ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  group_by(Class) %>% 
  count()
```

```{r}
ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  group_by(Class) %>% 
  summarise(across(`2020 Mar`:`2020 Aug`, median)) %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, names_to = "datename") %>% 
  mutate(datename = yearmonth(datename),
         Class = as.factor(Class)) %>% 
  ggplot(aes(x = datename, y = value, colour = Class)) +
  geom_line()
```


```{r}
df <- 
  ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"), 
            drug)) %>% 
  mutate(Class = as.factor(Class)) %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, names_to = "datename")


df %>% 
  split(.$datename) %>% 
  map(~aov(value ~ Class, data = df)) %>% 
  map(summary) 

df %>% 
  split(.$datename) %>% 
  map(~aov(value ~ Class, data = df)) %>% 
  map(TukeyHSD)
```


* Class 1
  * n = 58
  * High in Mar, slight depression for Apr & May, as forecast in Jun & Jul, low levels in Aug. Moderate variability throughout.
  * Stockpiling followed by reduced prescribing for two months before returning to "normal" for two months
* Class 2
  * n = 26
  * Very high in Mar, decreased prescribing in Apr, then extremely variable prescribing for the remaining months.
  * Very high levels of stockpiling followed by chaotic prescribing.
* Class 3
  * n = 125
  * Elevated levels of prescribing in Mar, as forecast in Apr, slight reduction in May, as forecast in Jun & Jul, then reduced prescribing in Aug. Very low levels of variability.
  * Business as usual with limited stockpiling
* Class 4
  * n = 85
  * High levels of prescribing in Mar & Apr, as forecast May, slight elevation in Jun & Jul, slight depression in Aug but still higher than others. Low levels of variability.
* Class 5
  * n = 72
  * High in Mar, as forecast in Apr, low levels in May, as forecast in Jun & Jul, low levels in Aug. Low levels of variability.
* Class 6
  * n = 36
  * High in Mar, extremely variable in Apr with prescribing as forecast, variable levels just below forecast, reduced variability and low levels of prescribing in Jun, as forecast in Jul, and low levels in Aug.


##### Weka data

```{r, ace-weka-prop}
ace_prop_lpa$model_2_class_6 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, is.character, practice_id), Class) %>% 
  mutate(across(is.numeric, scale)) %>% 
  write_csv("../data/weka/ace_prop.csv")
```


##### Multinomial logistic regression

```{r, ace-multinom-prop-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

ace_multinom_prop_data <-
  ace_prop_lpa$model_2_class_6 %>%
  get_data() %>%
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>%
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>%
  mutate(gp_load = npat/ngp) %>%
  select(Class, pm_65, p_fem, wimd2019, dispensing, ngp, gp_load, hboard) %>%
  mutate(Class = as.factor(Class),
        hboard = as.factor(hboard),
        # across(where(is.numeric), ~normalize(.))
        )

# ace_multinom_prop_data <-
#   ace_prop_lpa$model_2_class_6 %>%
#   get_data() %>%
#   inner_join(dis_pca_scores, by = c("regional_unit" = "practice_id")) %>%
#   inner_join(select(filter(gp, year == 2020), 
#                     c(practiceid, hboard, wimd2019, dispensing, ngp, npat, p_fem, pm_65)), 
#              by = c("regional_unit" = "practiceid")) %>%
#   select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"), drug, regional_unit)) %>%
#   mutate(Class = as.factor(Class),
#          gp_load = npat/ngp,
#          ngp = NULL,
#          across(where(is.numeric), ~normalize(.)))


ace_multinom_prop_data %>% 
  DataExplorer::plot_correlation()

car::vif(lm(as.numeric(Class) ~ ., data = ace_multinom_prop_data))

```


###### Class 1 ref

```{r, ace-multinom-prop-ref1}
# Class 1 as ref class
ace_multinom_prop_data$Class <- relevel(ace_multinom_prop_data$Class, ref = "1")
ace_prop_m1 <- 
  ace_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_prop_m1)
print("relative risk"); exp(coef(ace_prop_m1))

ace_prop_m1_z <- summary(ace_prop_m1)$coefficients/summary(ace_prop_m1)$standard.errors
#ace_m1_z

# Two-tailed z-test
print("Wald test p-value")
ace_prop_m1_p <- (1 - pnorm(abs(ace_prop_m1_z), 0, 1)) * 2
ace_prop_m1_p
```


```{r}
coef(ace_prop_m1) %>% 
  as_tibble(rownames = "Class") %>% 
  pivot_longer(cols = `(Intercept)`:hboard29, values_to = "coefficient",
               names_to = "variable") %>% 
  left_join(summary(ace_prop_m1)$standard.errors %>% 
  as_tibble(rownames = "Class") %>% 
  pivot_longer(cols = `(Intercept)`:hboard29, values_to = "se",
               names_to = "variable")) %>% 
  ggplot(aes(x = coefficient, y = variable, group = as.factor(Class), colour = as.factor(Class))) +
  geom_point(position = position_dodge(width = .5)) +
  geom_errorbarh(aes(xmin = coefficient - 2 * se, xmax = coefficient + 2 * se),
                 position = position_dodge(width = .5))

ace_multinom_prop_data %>% 
  mutate(across(is.numeric, scale)) %>% 
  pivot_longer(cols = where(is.numeric), names_to = "variable") %>% 
  ggplot(aes(x = variable, y = value, colour = Class)) +
  geom_boxplot()


sjPlot::plot_model(ace_prop_m1, type = "pred", terms = c("pm_65 [all]", "dispensing"))
sjPlot::plot_model(ace_prop_m1, type = "eff")
```


###### Class 2 ref

```{r, ace-multinom-prop-ref2}
# Class 2 as ref class
ace_multinom_prop_data$Class <- relevel(ace_multinom_prop_data$Class, ref = "2")
ace_prop_m2 <- 
  ace_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_prop_m2)
print("relative risk"); exp(coef(ace_prop_m2))

ace_prop_m2_z <- summary(ace_prop_m2)$coefficients/summary(ace_prop_m2)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
ace_prop_m2_p <- (1 - pnorm(abs(ace_prop_m2_z), 0, 1)) * 2
ace_prop_m2_p
```


###### Class 3 ref

```{r, ace-multinom-prop-ref3}
# Class 3 as ref class
ace_multinom_prop_data$Class <- relevel(ace_multinom_prop_data$Class, ref = "3")
ace_prop_m3 <- 
  ace_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_prop_m3)
print("relative risk"); exp(coef(ace_prop_m3))

ace_prop_m3_z <- summary(ace_prop_m3)$coefficients/summary(ace_prop_m3)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
ace_prop_m3_p <- (1 - pnorm(abs(ace_prop_m3_z), 0, 1)) * 2
ace_prop_m3_p
```


###### Class 4 ref

```{r, ace-multinom-prop-ref4}
# Class 2 as ref class
ace_multinom_prop_data$Class <- relevel(ace_multinom_prop_data$Class, ref = "4")
ace_prop_m4 <- 
  ace_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_prop_m4)
print("relative risk"); exp(coef(ace_prop_m4))

ace_prop_m4_z <- summary(ace_prop_m4)$coefficients/summary(ace_prop_m4)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
ace_prop_m4_p <- (1 - pnorm(abs(ace_prop_m4_z), 0, 1)) * 2
ace_prop_m4_p
```


###### Class 5 ref

```{r, ace-multinom-prop-ref5}
# Class 2 as ref class
ace_multinom_prop_data$Class <- relevel(ace_multinom_prop_data$Class, ref = "5")
ace_prop_m5 <- 
  ace_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(ace_prop_m5)
print("relative risk"); exp(coef(ace_prop_m5))

ace_prop_m5_z <- summary(ace_prop_m5)$coefficients/summary(ace_prop_m5)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
ace_prop_m5_p <- (1 - pnorm(abs(ace_prop_m5_z), 0, 1)) * 2
ace_prop_m5_p
```

### adreno
#### difference
##### LPA estimation

```{r, adreno-lpa-diff}
tictoc::tic()
adreno_lpa <- 
  differences_wide %>% 
  filter(drug == "adreno") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:6,
                    models = c(1:3))
tictoc::toc()
```


##### LPA model selection

```{r, adreno-fits-diff}
adreno_lpa

adreno_lpa_fits <- compare_solutions(adreno_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
adreno_lpa_fits

adreno_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* AIC, BIC, SABIC suggest 6, 5, 6 classes with model 2 being the best fit
* BLRT suggests < 6 classes
  * AIC and SABIC suggest 5 classes when BLRT threshold applied
* Entropy suggests 
* Selected model 2 with 5 classes.


```{r}
adreno_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "adreno") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, adreno-profile-vis-diff}
adreno_lpa$model_2_class_5 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```

* Class 1 - 
* Class 2 - 
* Class 3 - 
* Class 4 - 


##### Weka data

```{r, adreno-weka-diff}
adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, where(is.character), practice_id), Class) %>% 
  mutate(across(where(is.numeric), scale)) %>% 
  write_csv("../data/weka/adreno.csv")
```


##### Multinomial logistic regression

```{r, adreno-multinom-diff-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

adreno_multinom_data <- 
  adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>% 
  mutate(gp_load = npat/ngp) %>% 
  select(Class, pm_65, p_fem, hyp, ast, wimd2019, dispensing, ngp, gp_load, hboard) %>% 
  mutate(Class = as.factor(Class),
         hboard = as.factor(hboard),
         across(where(is.numeric), ~normalize(.)))

adreno_multinom_data %>% 
  DataExplorer::plot_correlation()

```


###### Class 1 ref

```{r, adreno-multinom-diff-ref1}
# Class 1 as ref class
adreno_multinom_data$Class <- relevel(adreno_multinom_data$Class, ref = "1")
adreno_m1 <- 
  adreno_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_m1)
print("relative risk"); exp(coef(adreno_m1))

adreno_m1_z <- summary(adreno_m1)$coefficients/summary(adreno_m1)$standard.errors
#adreno_m1_z

# Two-tailed z-test
print("Wald test p-value")
adreno_m1_p <- (1 - pnorm(abs(adreno_m1_z), 0, 1)) * 2
adreno_m1_p
```


###### Class 2 ref

```{r, adreno-multinom-diff-ref2}
# Class 2 as ref class
adreno_multinom_data$Class <- relevel(adreno_multinom_data$Class, ref = "2")
adreno_m2 <- 
  adreno_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_m2)
print("relative risk"); exp(coef(adreno_m2))

adreno_m2_z <- summary(adreno_m2)$coefficients/summary(adreno_m2)$standard.errors
# adreno_m2_z

# Two-tailed z-test
print("Wald test p-value")
adreno_m2_p <- (1 - pnorm(abs(adreno_m2_z), 0, 1)) * 2
adreno_m2_p
```


###### Class 3 ref

```{r, adreno-multinom-diff-ref3}
# Class 3 as ref class
adreno_multinom_data$Class <- relevel(adreno_multinom_data$Class, ref = "3")
adreno_m3 <- 
  adreno_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_m3)
print("relative risk"); exp(coef(adreno_m3))

adreno_m3_z <- summary(adreno_m3)$coefficients/summary(adreno_m3)$standard.errors
# adreno_m3_z

# Two-tailed z-test
print("Wald test p-value")
adreno_m3_p <- (1 - pnorm(abs(adreno_m3_z), 0, 1)) * 2
adreno_m3_p
```


###### Class 4 ref

```{r, adreno-multinom-diff-ref4}
# Class 4 as ref class
adreno_multinom_data$Class <- relevel(adreno_multinom_data$Class, ref = "4")
adreno_m4 <- 
  adreno_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_m4)
print("relative risk"); exp(coef(adreno_m4))

adreno_m4_z <- summary(adreno_m4)$coefficients/summary(adreno_m4)$standard.errors
# adreno_m4_z

# Two-tailed z-test
print("Wald test p-value")
adreno_m4_p <- (1 - pnorm(abs(adreno_m4_z), 0, 1)) * 2
adreno_m4_p
```




```{r}
adreno_multinom_data %>% 
  group_by(Class) %>% 
  summarise(dispensing = sum(if_else(as.character(dispensing) == "Yes", 1, 0))/n())
```




####

```{r, adreno-lpa}
adreno_lpa <- 
  differences_wide %>% 
  filter(drug == "adreno") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
```


```{r}
adreno_lpa
compare_solutions(adreno_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p"))
```


```{r}
adreno_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "adreno") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(4,5,6,8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```

* Different fit statistics suggest different models best fit the data. Increasing the number of classes does not change the shapes of the profiles, it merely splits existing profiles into smaller units.
* Retain the five class solution based on principle of parsimony and interpretability. 

```{r}
adreno_lpa$model_2_class_5 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  ggplot(aes(x = datename, y = difference, group = rowname, colour = rowname)) +
  geom_line(alpha = .1) +
  facet_wrap(~Class) +
  theme(legend.position = "none")

adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75)) +
  theme(legend.position = "none")

df <- 
  adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) 

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

adreno_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  # pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
  #              names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  # summary() %>% 
  TukeyHSD()
```

#### proportion
##### LPA estimation

```{r}
proportions %>% 
  filter(drug == "adreno") %>% 
  ggplot(aes(x = prop)) + 
  geom_histogram() +
  facet_wrap(~as.factor(datename))
```


```{r, adreno-lpa-prop}
tictoc::tic()
adreno_prop_lpa <- 
  proportions_wide %>% 
  filter(drug == "adreno") %>%
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
tictoc::toc()
```

##### LPA model selection

```{r, adreno-fits-prop}
adreno_prop_lpa

adreno_prop_lpa_fits <- compare_solutions(adreno_prop_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
adreno_prop_lpa_fits

adreno_prop_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* Selected model 2 with 4 classes.


```{r, adreno-prop-plots}
adreno_prop_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "adreno") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, adreno-profile-vis-prop}
adreno_prop_lpa$model_2_class_4 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  adreno_prop_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

adreno_prop_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

adreno_prop_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```

* Class 1 - 
* Class 2 - 
* Class 3 - 
* Class 4 - 


##### Weka data

```{r, adreno-weka-prop}
adreno_prop_lpa$model_2_class_4 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, is.character, practice_id), Class) %>% 
  mutate(across(is.numeric, scale)) %>% 
  write_csv("../data/weka/adreno_prop.csv")
```


##### Multinomial logistic regression

```{r, adreno-multinom-prop-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

adreno_multinom_prop_data <-
  adreno_prop_lpa$model_2_class_6 %>%
  get_data() %>%
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>%
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>%
  mutate(gp_load = npat/ngp) %>%
  select(Class, pm_65, p_fem, hyp, hf, chd, ast, wimd2019, dispensing, ngp, gp_load, hboard) %>%
  mutate(Class = as.factor(Class),
         hboard = as.factor(hboard),
         across(where(is.numeric), ~normalize(.)))

adreno_multinom_prop_data %>% 
  DataExplorer::plot_correlation()

car::vif(lm(as.numeric(Class) ~ ., data = adreno_multinom_prop_data))

```


###### Class 1 ref

```{r, adreno-multinom-prop-ref1}
# Class 1 as ref class
adreno_multinom_prop_data$Class <- relevel(adreno_multinom_prop_data$Class, ref = "1")
adreno_prop_m1 <- 
  adreno_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_prop_m1)
print("relative risk"); exp(coef(adreno_prop_m1))

adreno_prop_m1_z <- summary(adreno_prop_m1)$coefficients/summary(adreno_prop_m1)$standard.errors
#adreno_m1_z

# Two-tailed z-test
print("Wald test p-value")
adreno_prop_m1_p <- (1 - pnorm(abs(adreno_prop_m1_z), 0, 1)) * 2
adreno_prop_m1_p

```


###### Class 2 ref

```{r, adreno-multinom-prop-ref2}
# Class 2 as ref class
adreno_multinom_prop_data$Class <- relevel(adreno_multinom_prop_data$Class, ref = "2")
adreno_prop_m2 <- 
  adreno_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_prop_m2)
print("relative risk"); exp(coef(adreno_prop_m2))

adreno_prop_m2_z <- summary(adreno_prop_m2)$coefficients/summary(adreno_prop_m2)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
adreno_prop_m2_p <- (1 - pnorm(abs(adreno_prop_m2_z), 0, 1)) * 2
adreno_prop_m2_p
```


###### Class 3 ref

```{r, adreno-multinom-prop-ref3}
# Class 3 as ref class
adreno_multinom_prop_data$Class <- relevel(adreno_multinom_prop_data$Class, ref = "3")
adreno_prop_m3 <- 
  adreno_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_prop_m3)
print("relative risk"); exp(coef(adreno_prop_m3))

adreno_prop_m3_z <- summary(adreno_prop_m3)$coefficients/summary(adreno_prop_m3)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
adreno_prop_m3_p <- (1 - pnorm(abs(adreno_prop_m3_z), 0, 1)) * 2
adreno_prop_m3_p
```


###### Class 4 ref

```{r, adreno-multinom-prop-ref4}
# Class 2 as ref class
adreno_multinom_prop_data$Class <- relevel(adreno_multinom_prop_data$Class, ref = "4")
adreno_prop_m4 <- 
  adreno_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_prop_m4)
print("relative risk"); exp(coef(adreno_prop_m4))

adreno_prop_m4_z <- summary(adreno_prop_m4)$coefficients/summary(adreno_prop_m4)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
adreno_prop_m4_p <- (1 - pnorm(abs(adreno_prop_m4_z), 0, 1)) * 2
adreno_prop_m4_p
```


###### Class 5 ref

```{r, adreno-multinom-prop-ref5}
# Class 2 as ref class
adreno_multinom_prop_data$Class <- relevel(adreno_multinom_prop_data$Class, ref = "5")
adreno_prop_m5 <- 
  adreno_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(adreno_prop_m5)
print("relative risk"); exp(coef(adreno_prop_m5))

adreno_prop_m5_z <- summary(adreno_prop_m5)$coefficients/summary(adreno_prop_m5)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
adreno_prop_m5_p <- (1 - pnorm(abs(adreno_prop_m5_z), 0, 1)) * 2
adreno_prop_m5_p
```



### azithro

```{r, azithro-lpa}
azithro_lpa <- 
  differences_wide %>% 
  filter(drug == "azithro") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
```


```{r, azithro-fits}
azithro_lpa
compare_solutions(azithro_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p"))
```


```{r}
azithro_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "azithro") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:6),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```

* 

```{r, ac-profile-vis}
azithro_lpa$model_2_class_4 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  azithro_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75)) +
  theme(legend.position = "none")

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

azithro_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

azithro_lpa$model_2_class_4 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```


### contra
#### difference
##### LPA estimation

```{r, contra-lpa-diff}
tictoc::tic()
contra_lpa <- 
  differences_wide %>% 
  filter(drug == "contra") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:6,
                    models = c(1:3))
tictoc::toc()
```


##### LPA model selection

```{r, contra-fits-diff}
contra_lpa

contra_lpa_fits <- compare_solutions(contra_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
contra_lpa_fits

contra_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* AIC, BIC, SABIC suggest 6, 5, 6 classes with model 2 being the best fit
* BLRT suggests < 6 classes
  * AIC and SABIC suggest 5 classes when BLRT threshold applied
* Entropy suggests 
* Selected model 2 with 3 classes.


```{r}
contra_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "contra") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, contra-profile-vis-diff}
contra_lpa$model_2_class_3 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  contra_lpa$model_2_class_3 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

contra_lpa$model_2_class_3 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

contra_lpa$model_2_class_3 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```

* Class 1 - 
* Class 2 - 
* Class 3 - 
* Class 4 - 


##### Weka data

```{r, contra-weka-diff}
contra_lpa$model_2_class_3 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, where(is.character), practice_id), Class) %>% 
  mutate(across(where(is.numeric), scale)) %>% 
  write_csv("../data/weka/contra.csv")
```


##### Multinomial logistic regression

```{r, contra-multinom-diff-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

contra_multinom_data <- 
  contra_lpa$model_2_class_3 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>% 
  mutate(gp_load = npat/ngp) %>% 
  select(Class, pm_65, p_fem, hyp, ast, wimd2019, dispensing, ngp, gp_load, hboard) %>% 
  mutate(Class = as.factor(Class),
         hboard = as.factor(hboard),
         across(where(is.numeric), ~normalize(.)))

contra_multinom_data %>% 
  DataExplorer::plot_correlation()

```


###### Class 1 ref

```{r, contra-multinom-diff-ref1}
# Class 1 as ref class
contra_multinom_data$Class <- relevel(contra_multinom_data$Class, ref = "1")
contra_m1 <- 
  contra_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_m1)
print("relative risk"); exp(coef(contra_m1))

contra_m1_z <- summary(contra_m1)$coefficients/summary(contra_m1)$standard.errors
#contra_m1_z

# Two-tailed z-test
print("Wald test p-value")
contra_m1_p <- (1 - pnorm(abs(contra_m1_z), 0, 1)) * 2
contra_m1_p
```


###### Class 2 ref

```{r, contra-multinom-diff-ref2}
# Class 2 as ref class
contra_multinom_data$Class <- relevel(contra_multinom_data$Class, ref = "2")
contra_m2 <- 
  contra_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_m2)
print("relative risk"); exp(coef(contra_m2))

contra_m2_z <- summary(contra_m2)$coefficients/summary(contra_m2)$standard.errors
# contra_m2_z

# Two-tailed z-test
print("Wald test p-value")
contra_m2_p <- (1 - pnorm(abs(contra_m2_z), 0, 1)) * 2
contra_m2_p
```


###### Class 3 ref

```{r, contra-multinom-diff-ref3}
# Class 3 as ref class
contra_multinom_data$Class <- relevel(contra_multinom_data$Class, ref = "3")
contra_m3 <- 
  contra_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_m3)
print("relative risk"); exp(coef(contra_m3))

contra_m3_z <- summary(contra_m3)$coefficients/summary(contra_m3)$standard.errors
# contra_m3_z

# Two-tailed z-test
print("Wald test p-value")
contra_m3_p <- (1 - pnorm(abs(contra_m3_z), 0, 1)) * 2
contra_m3_p
```


###### Class 4 ref

```{r, contra-multinom-diff-ref4}
# Class 4 as ref class
contra_multinom_data$Class <- relevel(contra_multinom_data$Class, ref = "4")
contra_m4 <- 
  contra_multinom_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_m4)
print("relative risk"); exp(coef(contra_m4))

contra_m4_z <- summary(contra_m4)$coefficients/summary(contra_m4)$standard.errors
# contra_m4_z

# Two-tailed z-test
print("Wald test p-value")
contra_m4_p <- (1 - pnorm(abs(contra_m4_z), 0, 1)) * 2
contra_m4_p
```




```{r}
contra_multinom_data %>% 
  group_by(Class) %>% 
  summarise(dispensing = sum(if_else(as.character(dispensing) == "Yes", 1, 0))/n())
```




####

```{r, contra-lpa}
contra_lpa <- 
  differences_wide %>% 
  filter(drug == "contra") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
```


```{r}
contra_lpa
compare_solutions(contra_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p"))
```


```{r}
contra_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "contra") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(4,5,6,8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```

* Different fit statistics suggest different models best fit the data. Increasing the number of classes does not change the shapes of the profiles, it merely splits existing profiles into smaller units.
* Retain the five class solution based on principle of parsimony and interpretability. 

```{r}
contra_lpa$model_2_class_5 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

contra_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  ggplot(aes(x = datename, y = difference, group = rowname, colour = rowname)) +
  geom_line(alpha = .1) +
  facet_wrap(~Class) +
  theme(legend.position = "none")

contra_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75)) +
  theme(legend.position = "none")

df <- 
  contra_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) 

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .1) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

contra_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  # pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
  #              names_to = "datename") %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  # summary() %>% 
  TukeyHSD()
```

#### proportion
##### LPA estimation

```{r}
proportions %>% 
  filter(drug == "contra") %>% 
  ggplot(aes(x = prop)) + 
  geom_histogram() +
  facet_wrap(~as.factor(datename))
```


```{r, contra-lpa-prop}
tictoc::tic()
contra_prop_lpa <- 
  proportions_wide %>% 
  filter(drug == "contra") %>%
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = 1:8,
                    models = c(1:3))
tictoc::toc()
```

##### LPA model selection

```{r, contra-fits-prop}
contra_prop_lpa

contra_prop_lpa_fits <- compare_solutions(contra_prop_lpa, statistics = c("BIC", "AIC", "SABIC", "BLRT_p", "Entropy"))
contra_prop_lpa_fits

contra_prop_lpa_fits$fits %>% 
  mutate(Model = as.factor(Model),
         Classes = as.factor(Classes)) %>% 
  pivot_longer(names_to = "IC", cols = c(AIC, BIC, SABIC, Entropy, prob_min, n_min)) %>% 
  select(-c(LogLik, AWE, CAIC, CLC, KIC, ICL)) %>% 
  ggplot(aes(x = Classes, colour = Model, group = Model)) +
  geom_line(aes(y = value)) +
  facet_wrap(~IC, scales = "free")

```

* Selected model 2 with 3 classes.


```{r, contra-prop-plots}
contra_prop_lpa %>%
  plot_profiles(rawdata = FALSE, sd = FALSE)

differences_wide %>% 
  filter(drug == "contra") %>% 
  estimate_profiles(df = ., 
                    select_vars = c("2020 Mar", "2020 Apr", "2020 May", 
                                    "2020 Jun", "2020 Jul", "2020 Aug"),
                    n_profiles = c(3:8),
                    models = 2) %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, contra-profile-vis-prop}
contra_prop_lpa$model_2_class_5 %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)

df <- 
  contra_prop_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  pivot_longer(cols = `2020 Mar`:`2020 Aug`, values_to = "difference", 
               names_to = "datename") %>% 
  mutate(Class = as.factor(Class),
         datename = as_factor(datename)) 

df %>% 
  ggplot(aes(x = datename, y = difference, colour = Class)) +
  geom_boxplot() +
  geom_point(alpha = .1, position=position_jitterdodge(dodge.width=0.75))

df %>% 
  ggplot(aes(x = datename, y = difference)) +
  geom_line(aes(colour = as.factor(rowname), group = rowname), alpha = .2) +
  stat_summary(fun = "mean") +
  facet_wrap(~Class) +
  theme(legend.position = "none")

contra_prop_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  summary()

contra_prop_lpa$model_2_class_5 %>% 
  get_data() %>% 
  select(-c(model_number, classes_number, starts_with("CPROB"))) %>% 
  rownames_to_column() %>% 
  mutate(Class = as.factor(Class)) %>% 
  aov(`2020 Mar` ~ Class, data = .) %>% 
  TukeyHSD()
```

* Class 1 - 
* Class 2 - 
* Class 3 - 
* Class 4 - 


##### Weka data

```{r, contra-weka-prop}
contra_prop_lpa$model_2_class_5 %>% 
  get_data() %>% 
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>% 
  select(-c(model_number:year, is.character, practice_id), Class) %>% 
  mutate(across(is.numeric, scale)) %>% 
  write_csv("../data/weka/contra_prop.csv")
```


##### Multinomial logistic regression

```{r, contra-multinom-prop-data}
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}

contra_multinom_prop_data <-
  contra_prop_lpa$model_2_class_5 %>%
  get_data() %>%
  inner_join(filter(gp, year == 2020), by = c("regional_unit" = "practiceid")) %>%
  select(-c(model_number, classes_number, starts_with("2020 "), starts_with("CPROB"))) %>%
  mutate(gp_load = npat/ngp) %>%
  select(Class, pm_65, p_fem, hyp, hf, chd, ast, wimd2019, dispensing, ngp, gp_load, hboard) %>%
  mutate(Class = as.factor(Class),
         hboard = as.factor(hboard),
         across(where(is.numeric), ~normalize(.)))

contra_multinom_prop_data %>% 
  DataExplorer::plot_correlation()

car::vif(lm(as.numeric(Class) ~ ., data = contra_multinom_prop_data))

```


###### Class 1 ref

```{r, contra-multinom-prop-ref1}
# Class 1 as ref class
contra_multinom_prop_data$Class <- relevel(contra_multinom_prop_data$Class, ref = "1")
contra_prop_m1 <- 
  contra_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_prop_m1)
print("relative risk"); exp(coef(contra_prop_m1))

contra_prop_m1_z <- summary(contra_prop_m1)$coefficients/summary(contra_prop_m1)$standard.errors
#contra_m1_z

# Two-tailed z-test
print("Wald test p-value")
contra_prop_m1_p <- (1 - pnorm(abs(contra_prop_m1_z), 0, 1)) * 2
contra_prop_m1_p

```


###### Class 2 ref

```{r, contra-multinom-prop-ref2}
# Class 2 as ref class
contra_multinom_prop_data$Class <- relevel(contra_multinom_prop_data$Class, ref = "2")
contra_prop_m2 <- 
  contra_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_prop_m2)
print("relative risk"); exp(coef(contra_prop_m2))

contra_prop_m2_z <- summary(contra_prop_m2)$coefficients/summary(contra_prop_m2)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
contra_prop_m2_p <- (1 - pnorm(abs(contra_prop_m2_z), 0, 1)) * 2
contra_prop_m2_p
```


###### Class 3 ref

```{r, contra-multinom-prop-ref3}
# Class 3 as ref class
contra_multinom_prop_data$Class <- relevel(contra_multinom_prop_data$Class, ref = "3")
contra_prop_m3 <- 
  contra_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_prop_m3)
print("relative risk"); exp(coef(contra_prop_m3))

contra_prop_m3_z <- summary(contra_prop_m3)$coefficients/summary(contra_prop_m3)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
contra_prop_m3_p <- (1 - pnorm(abs(contra_prop_m3_z), 0, 1)) * 2
contra_prop_m3_p
```


###### Class 4 ref

```{r, contra-multinom-prop-ref4}
# Class 2 as ref class
contra_multinom_prop_data$Class <- relevel(contra_multinom_prop_data$Class, ref = "4")
contra_prop_m4 <- 
  contra_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_prop_m4)
print("relative risk"); exp(coef(contra_prop_m4))

contra_prop_m4_z <- summary(contra_prop_m4)$coefficients/summary(contra_prop_m4)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
contra_prop_m4_p <- (1 - pnorm(abs(contra_prop_m4_z), 0, 1)) * 2
contra_prop_m4_p
```


###### Class 5 ref

```{r, contra-multinom-prop-ref5}
# Class 2 as ref class
contra_multinom_prop_data$Class <- relevel(contra_multinom_prop_data$Class, ref = "5")
contra_prop_m5 <- 
  contra_multinom_prop_data %>% 
  multinom(Class ~ ., family = "binomial", data = .) 

summary(contra_prop_m5)
print("relative risk"); exp(coef(contra_prop_m5))

contra_prop_m5_z <- summary(contra_prop_m5)$coefficients/summary(contra_prop_m5)$standard.errors

# Two-tailed z-test
print("Wald test p-value")
contra_prop_m5_p <- (1 - pnorm(abs(contra_prop_m5_z), 0, 1)) * 2
contra_prop_m5_p
```





### All

```{r, lpa-models-nested, include=FALSE}
tictoc::tic()
lpa_analysis <- 
  differences_wide %>% 
  anti_join(y = differences_wide %>% # These cause computation issues. Look at separately.
              filter(drug == "ace" & `2020 Jul` < -50),
            by = c("drug", "regional_unit")) %>%
  nest_by(drug) %>% 
  mutate(lpa_models = list(estimate_profiles(df = data[2:7],
                                      n_profiles = 1:8, 
                                      models = c(1:3))),
         lpa_fits = list(compare_solutions(lpa_models, 
                                           statistics = c("BIC", "AIC", "BLRT_p", "prob_min", "Entropy"))),
         lpa_plots = list(plot_profiles(lpa_models, 
                                        rawdata = FALSE, 
                                        sd = FALSE)),
         best_lpa_rn = as.numeric(list(lpa_fits$AHP)),
         best_lpa_fit = list(lpa_fits$fits[lpa_fits$AHP,]),
         best_lpa_model = flatten(list(lpa_models[lpa_fits$AHP])),
         classes = list(flatten(flatten(list(lpa_models[lpa_fits$AHP])))$model$classification),
         class_count = list(table(flatten(flatten(list(lpa_models[lpa_fits$AHP])))$model$classification)),
         lpa_class = list(bind_cols(drug = drug, 
                                    regional_unit = data$regional_unit, 
                                    lpa_class = classes)))
tictoc::toc()
```

```{r, lpa-best-model-plot, include=FALSE}
lpa_analysis <- 
  lpa_analysis %>% 
  mutate(best_lpa_model_plot = list(plot_profiles(best_lpa_model, 
                                                  rawdata = FALSE, 
                                                  sd = FALSE)),
         best_lpa_model_plot_lab = list(best_lpa_model_plot + 
                                          labs(title = drug)),
         best_lpa_cprob = list(select(best_lpa_model$dff,
                                      starts_with("CPROB"), Class)))

lpa_analysis %>% 
  pluck("best_lpa_cprob") %>% 
  set_names(drugs)

```

```{r, lpa-best-model-plot-2}
lpa_analysis$lpa_fits

lpa_analysis %>% 
  pluck("class_count") %>% 
  set_names(drugs) %>% 
  bind_rows(.id = "drug")

```


```{r}
lpa_analysis$lpa_fits %>% 
  set_names(drugs) %>% 
  pluck("cortico")

lpa_analysis$lpa_models %>% 
  set_names(drugs) %>% 
  pluck("cortico")

lpa_analysis$lpa_models %>% 
  set_names(drugs) %>% 
  pluck("cortico") %>% 
  pluck("model_2_class_6") %>% 
  plot_profiles(rawdata = FALSE, sd = FALSE)
```


```{r, lpa-best-model-class-assignment}
lpa_analysis %>% 
  pluck("lpa_class") %>% 
  bind_rows() %>% 
  pivot_wider(names_from = drug, names_prefix = "lpa_class_",
              values_from = lpa_class)

```


### Outliers

```{r, lpa-models, eval=FALSE}
drugs <- unique(as.character(differences$drug))

differences_wide <- 
  differences %>% 
  pivot_wider(names_from = datename, values_from = discrepancy)

system.time(differences_wide %>% 
              filter(drug == "oac") %>% 
              ungroup() %>% 
              select(`2020 Mar`:`2020 Aug`) %>% 
              estimate_profiles(df = ., n_profiles = 1:5, models = c(1:3, 6)))

lpaProfiles <- function(data, filter){
  data %>% 
    filter(drug == filter) %>% 
    ungroup() %>% 
    select(`2020 Mar`:`2020 Aug`) %>% 
    estimate_profiles(df = ., n_profiles = 1:5, models = c(1:3, 6))
}

plan(cluster)
system.time(lpa_fits <- 
              future_map(.x = drugs,
                         .f = ~lpaProfiles(differences_wide, .x)))
plan(sequential)

lpa_fits %>% 
  saveRDS("../data/models/lpa_fits.rds")
```


```{r, seperate-lpa-models, eval=FALSE}
lpaProfiles <- function(data, filter){
  data %>% 
    filter(drug == filter) %>% 
    ungroup() %>% 
    select(`2020 Mar`:`2020 Aug`) %>% 
    estimate_profiles(df = ., n_profiles = 1:6, models = c(1:3, 6))
}

tictoc::tic()
system.time(oac_lpa <- lpaProfiles(differences_wide, "oac"))
print("step 1")
print("step 2")
system.time(azithro_lpa <- lpaProfiles(differences_wide, "azithro"))
print("step 3")
system.time(contra_lpa <- lpaProfiles(differences_wide, "contra"))
print("step 4")
system.time(cortico_lpa <- lpaProfiles(differences_wide, "cortico"))
print("step 5")
system.time(hcq_lpa <- lpaProfiles(differences_wide, "hcq"))
print("step 6")
system.time(nsaid_lpa <- lpaProfiles(differences_wide, "nsaid"))
print("step 7")
system.time(vitd_lpa <- lpaProfiles(differences_wide, "vitd"))
print("step 8")
system.time(paracet_lpa <- lpaProfiles(differences_wide, "paracet"))
print("step 9")
#system.time(adreno_lpa <- lpaProfiles(differences_wide, "adreno"))
system.time(ace_lpa <- differences_wide %>%
              filter(drug == "ace") %>% 
              filter(`2020 Jul` > -50) %>% # Outliers causing computation problems
              estimate_profiles(df = .[3:8], 
                                n_profiles = 1:6, 
                                models = c(1:3, 6)))
print("step 10")
lpa_sep_fits <- list(ace_lpa, azithro_lpa, contra_lpa, cortico_lpa, 
                     hcq_lpa, nsaid_lpa, oac_lpa, paracet_lpa, vitd_lpa)
tictoc::toc()


```


```{r, adreno-lpa, eval=FALSE}
system.time(differences_wide %>% 
              filter(drug == "adreno") %>% 
              # filter(`2020 Jul` > -50) %>% # Outliers causing computation problems
              estimate_profiles(df = .[c(3:8)], 
                                n_profiles = 1:5, 
                                models = c(1:3,6)) %>% 
              plot_profiles(rawdata = FALSE))

## Models 1:3
# 2708.712 secs with df = .[c(3:5)]
# 63.237 secs with df = .[c(3:6)]
# 1101.290 secs with df = .[c(3:7)]
# 1618.723 secs with df = .[c(3:8)]
## Models 1:3, 6
# 2338.966 secs with df = .[c(3:8)]

differences_wide %>% 
  filter(drug == "adreno") %>% 
  ggplot(aes(x = `2020 May`)) +
  geom_histogram()
```


